{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general packages for data manipulation\n",
    "import pandas as pd\n",
    "#visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "#consistent sized plot \n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize']=12,5\n",
    "rcParams['axes.labelsize']=12\n",
    "rcParams['xtick.labelsize']=12\n",
    "rcParams['ytick.labelsize']=12\n",
    "#handle the warnings in the code\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "#text preprocessing libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "#import texthero\n",
    "#import texthero as hero\n",
    "#regular expressions\n",
    "import re\n",
    "#display pandas dataframe columns \n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load csv file as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment  source  label\n",
      "0  As a woman you shouldn't complain about cleani...  kaggle      0\n",
      "1  boy dats cold...tyga dwn bad for cuffin dat ho...  kaggle      1\n",
      "2  Dawg!!!! You ever fuck a bitch and she start t...  kaggle      1\n",
      "3  The shit you hear about me might be true or it...  kaggle      1\n",
      "4  The shit just blows me..claim you so faithful ...  kaggle      1\n",
      "(2398, 3)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\VSCode\\NLP4B_Football\\Own_model\\labeled_normalized_data.csv')\n",
    "\n",
    "#drop the first column because it is not necessary\n",
    "data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "\n",
    "#copy to a new dataframe\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find things to remove and how often they appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items found: 5 ['@soccerboy_04', '@bluprint_4', '@KingCuh', '@WestYourMajesty', '@']\n",
      "Total items found: 49 ['#Shots', '#2MW', '#HappyHumpDay', '#Eaglesnation', '#EarlyChristmas', '#CowboysNation', '#TehGodClan', '#Yankees', '#FreeMoneyMelle', '#oomf', '#scally', '#fixed', '#KingOfTheHill', '#UCFPINKPARTY', '#bum', '#hoesaintloyal', '#real', '#Pisces', '#GerrysHalloweenParty', '#MTVHottest', '#Yankees', '#ProtectTheAnimals', '#Damn', '#', '#blondeproblems', '#scally', '#History', '#frenchscally', '#YoureNotMyType', '#shitmybosssays', '#shitallysays', '#FreshRhymes', '#128514', '#JT2020Tour', '#50centmovie', '#ThankYouPaulForConfirmingLarry', '#NottingHill', '#8230', '#233', '#8230', '#RIPTALLT', '#65292', '#Tupac', '#afterearth', '#SNL', '#hoes', '#ShitFahdSays', '#redskins', '#1']\n",
      "Total items found: 2 ['https://x.com/dfb', 'https://youtu.be/8dIQ56YACvE']\n",
      "Total items found: 1829 [\"'\", '.', '!', '.', '.', ':', '.', '?', '.', \"'\", \"'\", '.', '#', '#', ',', '#', \"'\", '\"', '.', \"'\", '\"', '\"', '\"', \"'\", '?', '-', '-', '?', '.', '\"', '?', '#', ',', '!', \"'\", '\"', '/', '.', '!', '.', ',', '\"', '.', '\"', '\"', '\"', '!', \"'\", '#', '.', '\"', \"'\", '!', '\"', ',', '.', ',', '.', '\"', \"'\", '?', ':', '\"', \"'\", '.', \"'\", ',', \"'\", \"'\", '*', '.', ',', \"'\", '\"', '\"', '!', \"'\", '|', \"'\", '?', '\"', '!', '!', '.', \"'\", \"'\", \"'\", \"'\", '\"', ',', '\"', \"'\", '#', '.', '#', '.', '.', '\"', '.', \"'\", '\"', \"'\", '\"', \"'\", '.', \"'\", \"'\", '#', \"'\", ',', \"'\", '\"', '.', ',', '.', '?', '\"', '\"', '-', '\"', '\"', '\"', \"'\", '.', '/', '.', '\"', '.', '?', '?', \"'\", \"'\", '\"', '\"', '\"', \"'\", '\"', '.', \"'\", '!', \"'\", '.', \"'\", ':', '%', \"'\", '/', '!', \"'\", '\"', '#', '\"', '.', '\"', '!', '.', \"'\", \"'\", '@', '.', '\"', '-', '.', '?', \"'\", '\"', '#', '@', '\"', \"'\", '\"', '\"', \"'\", '\"', ',', '#', '\"', '-', '\"', \"'\", '\"', '\"', ',', '\"', \"'\", '.', \"'\", '\"', '-', \"'\", '\"', '\"', '\"', '.', '.', \"'\", \"'\", '\"', \"'\", '.', '\"', '\"', '.', '.', '\"', '\"', ',', '.', '?', \"'\", ',', \"'\", ',', '.', \"'\", '.', '?', '\"', '\"', '.', ',', ',', ',', '.', '@', '.', '#', '-', '.', '\"', '\"', ',', '\"', '.', '.', '\"', '#', '!', ':', \"'\", '!', \"'\", '\"', \"'\", '!', '?', \"'\", ',', \"'\", '.', \"'\", \"'\", \"'\", '\"', '\"', '\"', '\"', '?', '!', '=', '!', '!', '!', '!', \"'\", '!', \"'\", '\"', '.', \"'\", '.', '!', '\"', '.', '#', \"'\", '?', \"'\", \"'\", \"'\", '\"', ',', \"'\", ',', '.', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', '\"', ':', '.', \"'\", '-', '.', '.', ':', '…', ':', '.', '’', \"'\", '.', \"'\", '.', \"'\", '.', ':', '!', '.', \"'\", '.', '…', ':', ':', '.', '\"', '’', \"'\", '’', ':', '.', ':', \"'\", ':', '’', '’', ':', ':', '.', '.', '’', ':', ':', '?', '/', '.', '-', \"'\", \"'\", '.', '.', ':', '.', '!', \"'\", '.', ':', '’', \"'\", '.', '?', '.', ':', '.', \"'\", \"'\", ':', '.', \"'\", ':', '?', '(', \"'\", '=', '.', '’', ':', '.', '?', '.', '.', '.', ':', ':', ':', '’', '.', '-', ':', '.', '’', ':', '.', \"'\", \"'\", \"'\", '.', '!', '’', '.', ':', '“', '.', '.', ':', '<', '.', ':', ':', ':', '.', ':', '<', '?', '.', '!', '!', '.', '.', '.', '’', '.', '?', '!', ':', '!', \"'\", \"'\", '!', '!', '!', ':', '!', '.', \"'\", '.', '.', '?', ':', \"'\", '!', '!', '!', '.', '’', \"'\", '.', '.', '.', ':', '.', '!', ':', ':', \"'\", '.', '-', '?', '.', '’', '!', '.', \"'\", ':', '’', '?', ':', ':', '’', \"'\", \"'\", \"'\", '-', '.', '?', '.', '’', '’', '’', '’', \"'\", \"'\", \"'\", '.', '.', '.', '.', '?', '.', ':', '.', \"'\", '-', '.', ':', ':', '.', '.', '?', '?', '?', '!', '<', \"'\", '.', ':', '’', ':', \"'\", '-', '!', '.', \"'\", '.', '!', '.', '“', '’', '?', '.', '’', ':', ':', '!', '.', \"'\", ':', '.', '.', ':', '&', '.', '.', ':', ':', '/', ':', '…', ':', '’', '.', '*', '<', \"'\", \"'\", ':', ':', '…', '.', '’', ':', '.', '!', '.', '.', '.', '’', '.', '.', '.', \"'\", '-', '?', '.', ':', \"'\", '.', '.', '”', '.', '?', '?', '!', '’', '\"', \"'\", ':', ':', \"'\", ':', ':', ':', '’', '.', '.', '\"', ':', ':', \"'\", '!', '’', '!', ':', '.', ':', ':', ':', '.', ':', '.', ':', ':', ':', ':', ':', ':', '.', ':', '.', '&', ':', '=', ':', \"'\", ':', ':', '!', '.', '.', ':', '.', \"'\", ':', '.', '.', '!', \"'\", \"'\", ':', ':', ':', ':', ':', ':', '?', '.', ':', ':', ':', ':', \"'\", '-', ':', '.', ':', ':', \"'\", '?', ':', '?', '.', ':', '!', '.', '?', '.', ':', \"'\", '.', '\"', '!', ':', '.', \"'\", '.', '.', '’', \"'\", \"'\", '.', '.', '.', \"'\", \"'\", '’', '.', '!', '.', ':', '-', '?', \"'\", '.', '\"', '.', '.', '.', '’', '.', '-', \"'\", '.', '’', '“', '.', '.', '.', '’', '.', '!', '&', '.', '.', '‘', \"'\", '.', '!', '.', '#', '.', '?', '’', ':', '.', '.', '-', ':', \"'\", '’', \"'\", '…', ':', '<', \"'\", ':', ':', '?', '.', '.', '.', '.', ':', '.', \"'\", \"'\", \"'\", '’', ':', \"'\", '.', ':', '.', '’', '.', ':', '.', '.', '.', '.', \"'\", ':', \"'\", '/', '‘', ':', '.', '.', \"'\", \"'\", ':', '.', ':', '.', ':', '.', ':', '.', '!', ':', ':', ':', '’', '!', '?', '.', '.', '’', '-', '!', '?', '’', '‘', '’', ':', '-', \"'\", '?', ':', \"'\", \"'\", '.', \"'\", '-', '.', ':', \"'\", '.', \"'\", '.', ':', '-', ':', '.', '’', '.', '?', '.', ':', \"'\", \"'\", '.', \"'\", '’', '’', ':', '!', '&', \"'\", ':', '.', \"'\", '.', ':', '(', ':', \"'\", \"'\", '?', '.', \"'\", '.', '.', '\"', '.', '!', '.', \"'\", ':', '?', '?', ':', '-', ':', \"'\", \"'\", '-', '-', '?', ':', '£', '’', '!', ':', '.', \"'\", '.', ':', '.', '.', '.', '.', \"'\", '’', \"'\", '’', '/', '?', '.', '.', '.', '.', '-', ':', '.', '.', '’', \"'\", ':', '.', '’', '.', '…', '’', '.', '.', '.', ':', '’', '?', '.', '.', ':', \"'\", ':', '.', '-', '.', \"'\", '?', '.', '.', '?', '.', '!', '’', ':', '.', '.', '-', \"'\", ':', '.', '.', ':', '?', \"'\", '?', '!', '?', ':', \"'\", ':', '.', '.', '’', '?', '?', ':', \"'\", '.', ':', '!', '!', '.', '’', ':', '*', '?', '.', ':', '.', ':', ':', '?', '.', '’', '.', '?', '.', '.', \"'\", '&', '.', '.', '?', '.', '.', '…', '’', ':', '.', '’', '.', ':', '…', '.', '.', \"'\", '?', '.', '.', ':', ':', ':', '.', '-', '-', '-', \"'\", '\"', '’', '.', ':', '’', '.', \"'\", '.', ':', ':', ':', ':', '.', '!', '’', '.', ':', \"'\", '-', '-', '.', '.', '’', '.', '.', '?', '.', ':', ':', ':', '!', '’', '!', '.', ':', ':', \"'\", \"'\", '.', '.', ':', ':', ':', '.', '.', ':', '’', '.', ':', '.', '.', ':', \"'\", '£', \"'\", '-', '!', \"'\", ':', '!', '!', '’', '.', ':', '\"', ':', '‘', '.', '?', ':', ':', ':', ':', '.', ':', '.', ';', '’', '.', '’', ':', '.', '.', '!', '’', '.', '.', ':', '’', '/', ':', '.', '’', '.', ':', ':', '.', '?', '‘', \"'\", '!', '’', '.', \"'\", '.', '.', '!', '-', '.', ':', ':', '’', '!', '-', '.', '’', \"'\", '.', '‘', '.', '?', \"'\", '!', '-', '-', '.', \"'\", ':', '.', \"'\", ':', ':', '?', ':', ':', '-', ':', '’', '?', ':', ':', '-', \"'\", '-', '.', \"'\", '.', '.', '.', '.', '.', ':', ':', '.', '.', '.', '-', ':', '.', '.', '.', '.', '?', ':', \"'\", ':', '’', '!', ':', '.', '.', '…', ':', ':', '-', ':', '\"', \"'\", '/', '.', '.', \"'\", '’', '!', '.', \"'\", \"'\", '.', '.', '.', '.', '’', ':', \"'\", '.', '.', \"'\", '.', '!', '.', \"'\", \"'\", ':', '.', '?', '.', '.', '.', '!', '-', '?', '.', '?', '.', '’', \"'\", '.', '.', '.', '!', '(', ':', '.', ':', ':', '!', '.', ':', ':', ':', '-', '!', \"'\", '!', '!', ':', \"'\", \"'\", \"'\", '.', '<', '.', ':', '.', ':', '(', ':', ':', '!', ':', '\"', '…', \"'\", ':', ':', '.', '.', '.', ':', ':', '<', '.', '.', '.', ':', '.', ':', \"'\", '?', ':', '.', ':', ':', ':', ':', \"'\", '.', ':', '.', ':', '(', \"'\", '’', ':', '/', '’', ':', '.', ':', \"'\", \"'\", '!', ':', \"'\", '.', \"'\", '.', '!', ':', '.', ':', '.', \"'\", '’', '.', ':', \"'\", '<', '.', '’', ':', '.', '’', ',', '’', ',', \"'\", '’', ',', '-', ',', ',', '’', \"'\", '’', ',', '’', ',', ',', '.', '.', '.', '.', '.', '.', '.', \"'\", ':', ',', '…', '?', ',', '/', '?', '.', '.', ',', '-', '?', \"'\", '.', ',', '.', '!', ',', '’', \"'\", ',', ':', '-', '.', '…', '.', '.', ':', ',', '.', ',', ',', '.', '.', '?', '’', '?', '.', ',', '.', '?', ',', ':', ',', \"'\", ',', '’', '.', '(', '.', '!', '.', ',', '?', ',', '?', \"'\", ',', '.', '!', ',', '.', '.', \"'\", \"'\", '\\\\', '?', ',', ',', '.', \"'\", '?', '’', ',', '?', \"'\", ',', '-', '?', '’', '’', '’', ',', '-', '.', '+', '.', '.', ',', ',', ',', ',', '.', '.', '.', ',', \"'\", \"'\", '<', ':', \"'\", \"'\", ',', '\"', '-', '.', ',', '.', ',', '.', '*', '-', '’', ',', \"'\", '?', '.', '?', '.', \"'\", \"'\", '.', ',', '.', \"'\", ':', '.', ',', '-', '.', \"'\", ',', '.', '.', \"'\", ',', '.', '.', \"'\", '.', '/', \"'\", \"'\", '?', '.', ',', '’', '’', '’', ',', ',', ',', ',', '?', ',', '.', '-', '?', '’', '’', \"'\", ',', '/', \"'\", \"'\", ',', ',', ',', \"'\", '.', '.', \"'\", '-', '\"', ':', '.', ',', '-', '.', '-', \"'\", '-', \"'\", '’', '.', \"'\", '&', '’', ',', \"'\", '’', '’', '(', '.', '?', '’', '.', \"'\", '?', '’', '?', '!', '?', '.', \"'\", \"'\", ',', '-', \"'\", \"'\", '.', '.', \"'\", '?', '.', ',', '.', \"'\", \"'\", '?', '.', \"'\", '.', \"'\", '’', '-', ':', ',', \"'\", ',', '.', \"'\", '’', '?', '’', '.', ',', '!', '.', \"'\", ',', ':', '?', \"'\", '?', '?', \"'\", \"'\", '.', '.', \"'\", '’', '?', \"'\", '?', '?', ',', \"'\", '?', '?', '.', '-', '.', ',', \"'\", \"'\", '.', '.', \"'\", '.', '.', ',', '’', '.', '’', '.', '-', '.', '(', '.', \"'\", '.', '.', ',', \"'\", '.', '.', ',', '.', '.', '.', '.', \"'\", '.', ',', '.', ',', '-', '/', '.', '.', '.', '’', '’', '.', '“', ',', '(', '.', \"'\", '.', '.', '.', ',', ',', \"'\", ',', '.']\n",
      "Total items found: 10 ['88', '88', '18', '18', '18', '18', '18', '88', '18', '18']\n",
      "['88', '88', '18', '18', '18', '18', '18', '88', '18', '18']\n"
     ]
    }
   ],
   "source": [
    "# Function to check for pattern\n",
    "def check_for_pattern(regex, dataframe, column_name):\n",
    "    '''Function to check for how often a pattern appears in a dataframe column and returns a list of all the items found'''\n",
    "    pattern = re.compile(regex)\n",
    "    result = []\n",
    "    for i in range(len(dataframe[column_name])):\n",
    "        phrase = (re.findall(pattern, dataframe[column_name][i]))\n",
    "        if phrase != []:\n",
    "            result.append(phrase[0])\n",
    "    print(\"Total items found:\", len(result), result)\n",
    "    return result\n",
    "\n",
    "# Check for user handles\n",
    "user_handles = check_for_pattern(r'@[\\w]*', df, 'comment')\n",
    "\n",
    "# Check for hashtags\n",
    "hashtags = check_for_pattern(r'#[\\w]*', df, 'comment')\n",
    "\n",
    "# Check for URLs\n",
    "urls = check_for_pattern(r'https?://[A-Za-z0-9./]+', df, 'comment')\n",
    "\n",
    "# Check for punctuations\n",
    "punctuations = check_for_pattern(r'[^\\w\\s]', df, 'comment')\n",
    "\n",
    "# Check for numbers 18, 88, 1312\n",
    "numbers = check_for_pattern(r'18|88|1312', df, 'comment')\n",
    "#print rows with numbers 18, 88, 1312, show only the comment column and show the whole comment\n",
    "print(numbers)\n",
    "# --> no need to worry\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove these patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>I meanhow good is Bellingham Crazy watching hi...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Stop being a pussy son and shove that needle i...</td>\n",
       "      <td>kaggle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>Unbelievable penalty given How on earth did th...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>Id like to reaffirm that Rice has been the be...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>How often does Darren Fletcher say And theres ...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment   source  label\n",
       "1347  I meanhow good is Bellingham Crazy watching hi...  youtube      0\n",
       "468   Stop being a pussy son and shove that needle i...   kaggle      1\n",
       "1462  Unbelievable penalty given How on earth did th...  youtube      0\n",
       "2265   Id like to reaffirm that Rice has been the be...   reddit      0\n",
       "943   How often does Darren Fletcher say And theres ...  youtube      0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove user handles\n",
    "df.replace(r'@[\\w]*', '', regex=True, inplace=True)\n",
    "\n",
    "# Remove hashtags\n",
    "df.replace(r'#[\\w]*', '', regex=True, inplace=True)\n",
    "\n",
    "# Remove URLs\n",
    "df.replace(r'https?://[A-Za-z0-9./]+', '', regex=True, inplace=True)\n",
    "\n",
    "# Remove punctuations\n",
    "df.replace(r'[^\\w\\s]', '', regex=True, inplace=True)\n",
    "\n",
    "# Remove digits\n",
    "df.replace(r'\\d+', '', regex=True, inplace=True)\n",
    "\n",
    "\n",
    "# show random 5 rows\n",
    "df.sample(5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decapitalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"comment\"] = df[\"comment\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>[shouldve, played, at, least, one, academy, pl...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>[i, know, utd, blundered, a, goal, lead, but, ...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>[a, lot, of, nigeria, fans, at, wembley]</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>[welbeck, and, ali, should, be, in, nigeria, t...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>[awakenbeerus, is, a, true, sports, savant, hi...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment   source  label\n",
       "1649  [shouldve, played, at, least, one, academy, pl...  youtube      0\n",
       "1387  [i, know, utd, blundered, a, goal, lead, but, ...  youtube      1\n",
       "1766           [a, lot, of, nigeria, fans, at, wembley]  youtube      0\n",
       "1805  [welbeck, and, ali, should, be, in, nigeria, t...  youtube      0\n",
       "1861  [awakenbeerus, is, a, true, sports, savant, hi...  youtube      0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize using Tokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "df['comment'] = df['comment'].apply(tokenizer.tokenize)\n",
    "\n",
    "#show random 5 rows\n",
    "df.sample(5, random_state=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>[meanhow, good, bellingham, crazy, watching, l...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>[stop, pussy, son, shove, needle, heart]</td>\n",
       "      <td>kaggle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>[unbelievable, penalty, given, earth, ref, give]</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>[id, like, reaffirm, rice, best, player, pitch]</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>[often, darren, fletcher, say, theres, chance]</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment   source  label\n",
       "1347  [meanhow, good, bellingham, crazy, watching, l...  youtube      0\n",
       "468            [stop, pussy, son, shove, needle, heart]   kaggle      1\n",
       "1462   [unbelievable, penalty, given, earth, ref, give]  youtube      0\n",
       "2265    [id, like, reaffirm, rice, best, player, pitch]   reddit      0\n",
       "943      [often, darren, fletcher, say, theres, chance]  youtube      0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#remove stopwords\n",
    "#nltk.download()\n",
    "stopwords = stopwords.words('english')\n",
    "df['comment'] = df['comment'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "\n",
    "#show random 5 rows\n",
    "df.sample(5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_nonalpha(text):\n",
    "    '''Function to remove the non-alphanumeric characters from the text'''\n",
    "    text = [word for word in text if word.isalpha()]\n",
    "    return text\n",
    "\n",
    "# Apply the function to the 'comment' column\n",
    "df['comment'] = df['comment'].apply(rem_nonalpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove digits from each comment in the DataFrame\n",
    "def remove_digits(comment):\n",
    "    return [item for item in comment if not item.isdigit()]\n",
    "\n",
    "# Apply the function to the 'comment' column\n",
    "df['comment'] = df['comment'].apply(remove_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for data balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label', data=df)\n",
    "plt.title('Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore most frequently used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('like', 204), ('bitch', 186), ('team', 139), ('game', 137), ('dont', 120), ('goal', 115), ('im', 113), ('england', 109), ('win', 103), ('one', 101)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "results = Counter()\n",
    "df['comment'].apply(results.update)\n",
    "#print the top 10 most common terms in the tweet \n",
    "print(results.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data formatting and predictive modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values: comment    0\n",
      "source     0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for null values\n",
    "print(f\"Null values: {df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>meanhow good bellingham crazy watching last ni...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>stop pussy son shove needle heart</td>\n",
       "      <td>kaggle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>unbelievable penalty given earth ref give</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>id like reaffirm rice best player pitch</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>often darren fletcher say theres chance</td>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment   source  label\n",
       "1347  meanhow good bellingham crazy watching last ni...  youtube      0\n",
       "468                   stop pussy son shove needle heart   kaggle      1\n",
       "1462          unbelievable penalty given earth ref give  youtube      0\n",
       "2265            id like reaffirm rice best player pitch   reddit      0\n",
       "943             often darren fletcher say theres chance  youtube      0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join comments back together\n",
    "df[\"comment\"] = df[\"comment\"].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# show random 5 rows\n",
    "df.sample(5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into input X and output y\n",
    "X = df['comment']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1918,) (480,) (1918,) (480,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1918, 4576) (480, 4576)\n"
     ]
    }
   ],
   "source": [
    "# use TfidfVectorizer to convert the raw documents into feature matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building: Ordinary logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinary logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "train_predictions = logreg.predict(X_train)\n",
    "test_predictions = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8952033368091762\n",
      "Test Accuracy: 0.8791666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# accuracy score\n",
    "print(f\"Train Accuracy: {accuracy_score(y_train, train_predictions)}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, test_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      1352\n",
      "           1       1.00      0.65      0.78       566\n",
      "\n",
      "    accuracy                           0.90      1918\n",
      "   macro avg       0.93      0.82      0.86      1918\n",
      "weighted avg       0.91      0.90      0.89      1918\n",
      "\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       355\n",
      "           1       0.99      0.54      0.70       125\n",
      "\n",
      "    accuracy                           0.88       480\n",
      "   macro avg       0.92      0.77      0.81       480\n",
      "weighted avg       0.89      0.88      0.87       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(\"Train Classification Report\")\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"Test Classification Report\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88      1352\n",
      "           1       0.67      1.00      0.80       566\n",
      "\n",
      "    accuracy                           0.85      1918\n",
      "   macro avg       0.83      0.90      0.84      1918\n",
      "weighted avg       0.90      0.85      0.86      1918\n",
      "\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.63      0.75       355\n",
      "           1       0.45      0.88      0.60       125\n",
      "\n",
      "    accuracy                           0.69       480\n",
      "   macro avg       0.69      0.75      0.67       480\n",
      "weighted avg       0.81      0.69      0.71       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the weight of the classes using inverse ratio\n",
    "weights = {0: 1.0, 1:13.0}\n",
    "#instantiate the logistic regression model and account for the weights to be applied for model coefficients update magnitude\n",
    "logreg = LogisticRegression(class_weight=weights)\n",
    "\n",
    "#fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "train_predictions = logreg.predict(X_train)\n",
    "test_predictions = logreg.predict(X_test)\n",
    "\n",
    "#classification report\n",
    "print(\"Train Classification Report\")\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"Test Classification Report\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': ['newton-cg', 'lbfgs', 'liblinear'], 'penalty': ['l1', 'l2', 'elasticnet'], 'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}\n"
     ]
    }
   ],
   "source": [
    "#grid search for best parameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['l1', 'l2', 'elasticnet']\n",
    "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "\n",
    "# check search space\n",
    "print(space)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuned Model with Balanced Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 72 is smaller than n_iter=100. Running 72 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "400 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.         0.77472592 0.73403956 0.72927475\n",
      "        nan        nan        nan        nan        nan 0.\n",
      " 0.77472592 0.76010776 0.73644562        nan        nan        nan\n",
      "        nan        nan 0.         0.77472592 0.77472592 0.76027902\n",
      "        nan        nan        nan        nan        nan 0.\n",
      " 0.77552784 0.77552784 0.77241622        nan        nan        nan\n",
      "        nan        nan 0.68218502 0.77639479 0.77639479 0.7770819\n",
      "        nan        nan        nan        nan        nan 0.78575769\n",
      " 0.77834377 0.77834377 0.77676333        nan        nan        nan\n",
      "        nan        nan 0.79446124 0.78022086 0.78022086 0.77947665\n",
      "        nan        nan        nan        nan        nan 0.77651693\n",
      " 0.76545257 0.76545257 0.76545257        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# define the model with balanced class weights\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "# define the number of folds\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# define the search\n",
    "search = RandomizedSearchCV(model, space, n_iter=100, scoring='f1', n_jobs=-1, cv=cv, random_state=1)\n",
    "# fit grid search on the training dataset\n",
    "result = search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight='balanced', penalty='l1',\n",
      "                   solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "# retrieve the best model\n",
    "best_model = result.best_estimator_\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the best model\n",
    "logreg = LogisticRegression(C=10, class_weight='balanced', penalty='l1', solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1352\n",
      "           1       1.00      0.99      1.00       566\n",
      "\n",
      "    accuracy                           1.00      1918\n",
      "   macro avg       1.00      1.00      1.00      1918\n",
      "weighted avg       1.00      1.00      1.00      1918\n",
      "\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       355\n",
      "           1       0.86      0.75      0.80       125\n",
      "\n",
      "    accuracy                           0.90       480\n",
      "   macro avg       0.89      0.85      0.87       480\n",
      "weighted avg       0.90      0.90      0.90       480\n",
      "\n",
      "Train Confusion Matrix\n",
      "[[1352    0]\n",
      " [   4  562]]\n",
      "Test Confusion Matrix\n",
      "[[340  15]\n",
      " [ 31  94]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#fit and predict\n",
    "logreg.fit(X_train, y_train)\n",
    "train_predictions = logreg.predict(X_train)\n",
    "test_predictions = logreg.predict(X_test)\n",
    "\n",
    "#classification report\n",
    "print(\"Train Classification Report\")\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"Test Classification Report\")\n",
    "print(classification_report(y_test, test_predictions))\n",
    "\n",
    "# confusion matrix\n",
    "print(\"Train Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, train_predictions))\n",
    "print(\"Test Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, test_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuned model with class weights proportional to the class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 72 is smaller than n_iter=100. Running 72 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight={0: 1.0, 1: 13}, penalty='l1',\n",
      "                   solver='liblinear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "400 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\proth\\.conda\\envs\\NLP4B_Project\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.         0.45570963 0.45570963 0.45570963\n",
      "        nan        nan        nan        nan        nan 0.\n",
      " 0.45570963 0.45570963 0.45570963        nan        nan        nan\n",
      "        nan        nan 0.45570963 0.45570963 0.45570963 0.45570963\n",
      "        nan        nan        nan        nan        nan 0.45570963\n",
      " 0.45570963 0.45570963 0.45570963        nan        nan        nan\n",
      "        nan        nan 0.45570963 0.45570963 0.45570963 0.45570963\n",
      "        nan        nan        nan        nan        nan 0.74729918\n",
      " 0.6332103  0.6332103  0.6328635         nan        nan        nan\n",
      "        nan        nan 0.77094741 0.75111236 0.75111236 0.75111236\n",
      "        nan        nan        nan        nan        nan 0.69866373\n",
      " 0.72952636 0.72891991 0.73058737        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#use the class weights to handle the imbalance in the labels\n",
    "weights = {0:1.0,1:13}\n",
    "\n",
    "#instantiate the logistic regression model and account for the weights to be applied for model coefficients update magnitude\n",
    "logreg = LogisticRegression(class_weight=weights)\n",
    "\n",
    "#define the number of folds\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "#define the search\n",
    "search = RandomizedSearchCV(logreg, space, n_iter=100, scoring='f1', n_jobs=-1, cv=cv, random_state=1)\n",
    "\n",
    "#fit grid search on the training dataset\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "#retrieve the best model\n",
    "best_model = result.best_estimator_\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1352\n",
      "           1       1.00      0.99      1.00       566\n",
      "\n",
      "    accuracy                           1.00      1918\n",
      "   macro avg       1.00      1.00      1.00      1918\n",
      "weighted avg       1.00      1.00      1.00      1918\n",
      "\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       355\n",
      "           1       0.82      0.78      0.80       125\n",
      "\n",
      "    accuracy                           0.90       480\n",
      "   macro avg       0.87      0.86      0.87       480\n",
      "weighted avg       0.90      0.90      0.90       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#instantiate the best model\n",
    "logreg = LogisticRegression(C=10, class_weight=weights, penalty='l1', solver='liblinear')\n",
    "\n",
    "#fit and predict\n",
    "logreg.fit(X_train, y_train)\n",
    "train_predictions = logreg.predict(X_train)\n",
    "test_predictions = logreg.predict(X_test)\n",
    "\n",
    "#classification report\n",
    "print(\"Train Classification Report\")\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"Test Classification Report\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix\n",
      "[[1352    0]\n",
      " [   4  562]]\n",
      "Test Confusion Matrix\n",
      "[[333  22]\n",
      " [ 27  98]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(\"Train Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, train_predictions))\n",
    "print(\"Test Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP4B_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
